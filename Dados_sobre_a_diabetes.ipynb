{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80phbvNArxAF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import neighbors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('diabetes.csv')"
      ],
      "metadata": {
        "id": "okLwiC4St7xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj2L-RyHumNm",
        "outputId": "d00c04a3-a167-4721-bc23-bfe4eceaf442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0              6      148             72             35        0  33.6   \n",
            "1              1       85             66             29        0  26.6   \n",
            "2              8      183             64              0        0  23.3   \n",
            "3              1       89             66             23       94  28.1   \n",
            "4              0      137             40             35      168  43.1   \n",
            "..           ...      ...            ...            ...      ...   ...   \n",
            "763           10      101             76             48      180  32.9   \n",
            "764            2      122             70             27        0  36.8   \n",
            "765            5      121             72             23      112  26.2   \n",
            "766            1      126             60              0        0  30.1   \n",
            "767            1       93             70             31        0  30.4   \n",
            "\n",
            "     DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                       0.627   50        1  \n",
            "1                       0.351   31        0  \n",
            "2                       0.672   32        1  \n",
            "3                       0.167   21        0  \n",
            "4                       2.288   33        1  \n",
            "..                        ...  ...      ...  \n",
            "763                     0.171   63        0  \n",
            "764                     0.340   27        0  \n",
            "765                     0.245   30        0  \n",
            "766                     0.349   47        1  \n",
            "767                     0.315   23        0  \n",
            "\n",
            "[768 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kNBhN0Vsuvam",
        "outputId": "07badb60-06df-4078-f63e-7705eede96de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a194450-226d-43d1-a411-c0c830143614\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a194450-226d-43d1-a411-c0c830143614')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a194450-226d-43d1-a411-c0c830143614 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a194450-226d-43d1-a411-c0c830143614');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51576a73-7927-4ff3-989b-31a769766051\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51576a73-7927-4ff3-989b-31a769766051')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51576a73-7927-4ff3-989b-31a769766051 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "xz29o1F3U-ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['Outcome']\n",
        "\n",
        "X = dataset[['Glucose']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, dataset['Glucose'], test_size=0.25, random_state=50)\n",
        "\n",
        "#Inicializar e treinar o classificador RF:\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8V3McN9mvA4l",
        "outputId": "7c9cfb61-3db4-468e-daab-82910b0d474d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicao = classifier.predict(X_test)\n",
        "acuracia = accuracy_score(y_test, predicao)\n",
        "report = classification_report(y_test, predicao)\n",
        "matriz_confusao = confusion_matrix(y_test, predicao)\n",
        "\n",
        "conclusao = classification_report(y_test, predicao)\n",
        "\n",
        "print(\"Acurácia:\", acuracia)\n",
        "print(\"Classificação:\")\n",
        "print(report)\n",
        "print(\"Matriz da confusão:\")\n",
        "print(matriz_confusao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfByLQh0n4a",
        "outputId": "a3f29f1a-5ee0-4053-d0bf-1ce5287f8320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.9635416666666666\n",
            "Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.00      0.00      0.00         2\n",
            "          65       0.00      0.00      0.00         1\n",
            "          67       0.00      0.00      0.00         0\n",
            "          71       1.00      1.00      1.00         1\n",
            "          73       1.00      1.00      1.00         2\n",
            "          74       1.00      1.00      1.00         1\n",
            "          75       1.00      1.00      1.00         1\n",
            "          77       1.00      1.00      1.00         1\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00         3\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       1.00      1.00      1.00         2\n",
            "          83       1.00      1.00      1.00         4\n",
            "          84       1.00      1.00      1.00         2\n",
            "          85       1.00      1.00      1.00         2\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         4\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         1\n",
            "          91       1.00      1.00      1.00         1\n",
            "          92       1.00      1.00      1.00         2\n",
            "          93       1.00      1.00      1.00         3\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         1\n",
            "          96       1.00      1.00      1.00         1\n",
            "          97       1.00      1.00      1.00         4\n",
            "          98       1.00      1.00      1.00         1\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         4\n",
            "         102       1.00      1.00      1.00         2\n",
            "         103       1.00      1.00      1.00         3\n",
            "         104       1.00      1.00      1.00         2\n",
            "         105       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         4\n",
            "         107       1.00      1.00      1.00         1\n",
            "         108       1.00      1.00      1.00         4\n",
            "         109       1.00      1.00      1.00         4\n",
            "         110       1.00      1.00      1.00         4\n",
            "         111       1.00      1.00      1.00         4\n",
            "         112       1.00      1.00      1.00         1\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      1.00      1.00         2\n",
            "         115       1.00      1.00      1.00         4\n",
            "         116       1.00      1.00      1.00         2\n",
            "         117       1.00      1.00      1.00         6\n",
            "         118       1.00      1.00      1.00         4\n",
            "         119       1.00      1.00      1.00         6\n",
            "         120       1.00      1.00      1.00         2\n",
            "         121       1.00      1.00      1.00         2\n",
            "         122       1.00      1.00      1.00         5\n",
            "         123       1.00      1.00      1.00         3\n",
            "         124       1.00      1.00      1.00         5\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         2\n",
            "         128       1.00      1.00      1.00         4\n",
            "         130       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         137       1.00      1.00      1.00         1\n",
            "         138       1.00      1.00      1.00         1\n",
            "         140       1.00      1.00      1.00         1\n",
            "         142       1.00      1.00      1.00         2\n",
            "         143       1.00      1.00      1.00         3\n",
            "         144       1.00      1.00      1.00         1\n",
            "         145       1.00      1.00      1.00         1\n",
            "         146       1.00      1.00      1.00         2\n",
            "         147       1.00      1.00      1.00         1\n",
            "         151       1.00      1.00      1.00         2\n",
            "         152       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         1\n",
            "         155       1.00      1.00      1.00         2\n",
            "         156       1.00      1.00      1.00         1\n",
            "         158       1.00      1.00      1.00         2\n",
            "         159       0.50      1.00      0.67         1\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       1.00      1.00      1.00         1\n",
            "         162       1.00      1.00      1.00         2\n",
            "         163       1.00      1.00      1.00         1\n",
            "         165       1.00      1.00      1.00         1\n",
            "         167       1.00      1.00      1.00         1\n",
            "         168       1.00      1.00      1.00         2\n",
            "         170       1.00      1.00      1.00         1\n",
            "         171       1.00      1.00      1.00         2\n",
            "         173       1.00      1.00      1.00         2\n",
            "         175       1.00      1.00      1.00         1\n",
            "         177       0.00      0.00      0.00         0\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      1.00      1.00         1\n",
            "         181       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         1\n",
            "         187       1.00      1.00      1.00         1\n",
            "         189       0.00      0.00      0.00         0\n",
            "         190       0.00      0.00      0.00         1\n",
            "         191       0.00      0.00      0.00         1\n",
            "         193       1.00      1.00      1.00         1\n",
            "         196       1.00      1.00      1.00         1\n",
            "         197       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.96       192\n",
            "   macro avg       0.89      0.90      0.90       192\n",
            "weighted avg       0.96      0.96      0.96       192\n",
            "\n",
            "Matriz da confusão:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [2 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Relatório da classificação:\")\n",
        "print(conclusao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxpFxRss5xcu",
        "outputId": "ea9555d4-507c-4f87-a982-2e064291c0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório da classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.00      0.00      0.00         2\n",
            "          65       0.00      0.00      0.00         1\n",
            "          67       0.00      0.00      0.00         0\n",
            "          71       1.00      1.00      1.00         1\n",
            "          73       1.00      1.00      1.00         2\n",
            "          74       1.00      1.00      1.00         1\n",
            "          75       1.00      1.00      1.00         1\n",
            "          77       1.00      1.00      1.00         1\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00         3\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       1.00      1.00      1.00         2\n",
            "          83       1.00      1.00      1.00         4\n",
            "          84       1.00      1.00      1.00         2\n",
            "          85       1.00      1.00      1.00         2\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         4\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         1\n",
            "          91       1.00      1.00      1.00         1\n",
            "          92       1.00      1.00      1.00         2\n",
            "          93       1.00      1.00      1.00         3\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         1\n",
            "          96       1.00      1.00      1.00         1\n",
            "          97       1.00      1.00      1.00         4\n",
            "          98       1.00      1.00      1.00         1\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         4\n",
            "         102       1.00      1.00      1.00         2\n",
            "         103       1.00      1.00      1.00         3\n",
            "         104       1.00      1.00      1.00         2\n",
            "         105       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         4\n",
            "         107       1.00      1.00      1.00         1\n",
            "         108       1.00      1.00      1.00         4\n",
            "         109       1.00      1.00      1.00         4\n",
            "         110       1.00      1.00      1.00         4\n",
            "         111       1.00      1.00      1.00         4\n",
            "         112       1.00      1.00      1.00         1\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      1.00      1.00         2\n",
            "         115       1.00      1.00      1.00         4\n",
            "         116       1.00      1.00      1.00         2\n",
            "         117       1.00      1.00      1.00         6\n",
            "         118       1.00      1.00      1.00         4\n",
            "         119       1.00      1.00      1.00         6\n",
            "         120       1.00      1.00      1.00         2\n",
            "         121       1.00      1.00      1.00         2\n",
            "         122       1.00      1.00      1.00         5\n",
            "         123       1.00      1.00      1.00         3\n",
            "         124       1.00      1.00      1.00         5\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         2\n",
            "         128       1.00      1.00      1.00         4\n",
            "         130       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         137       1.00      1.00      1.00         1\n",
            "         138       1.00      1.00      1.00         1\n",
            "         140       1.00      1.00      1.00         1\n",
            "         142       1.00      1.00      1.00         2\n",
            "         143       1.00      1.00      1.00         3\n",
            "         144       1.00      1.00      1.00         1\n",
            "         145       1.00      1.00      1.00         1\n",
            "         146       1.00      1.00      1.00         2\n",
            "         147       1.00      1.00      1.00         1\n",
            "         151       1.00      1.00      1.00         2\n",
            "         152       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         1\n",
            "         155       1.00      1.00      1.00         2\n",
            "         156       1.00      1.00      1.00         1\n",
            "         158       1.00      1.00      1.00         2\n",
            "         159       0.50      1.00      0.67         1\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       1.00      1.00      1.00         1\n",
            "         162       1.00      1.00      1.00         2\n",
            "         163       1.00      1.00      1.00         1\n",
            "         165       1.00      1.00      1.00         1\n",
            "         167       1.00      1.00      1.00         1\n",
            "         168       1.00      1.00      1.00         2\n",
            "         170       1.00      1.00      1.00         1\n",
            "         171       1.00      1.00      1.00         2\n",
            "         173       1.00      1.00      1.00         2\n",
            "         175       1.00      1.00      1.00         1\n",
            "         177       0.00      0.00      0.00         0\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      1.00      1.00         1\n",
            "         181       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         1\n",
            "         187       1.00      1.00      1.00         1\n",
            "         189       0.00      0.00      0.00         0\n",
            "         190       0.00      0.00      0.00         1\n",
            "         191       0.00      0.00      0.00         1\n",
            "         193       1.00      1.00      1.00         1\n",
            "         196       1.00      1.00      1.00         1\n",
            "         197       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.96       192\n",
            "   macro avg       0.89      0.90      0.90       192\n",
            "weighted avg       0.96      0.96      0.96       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arvore_decisao = DecisionTreeClassifier()\n",
        "\n",
        "arvore_decisao.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "b1TrXKNoSGZR",
        "outputId": "8e5a7660-c81e-4f22-b018-9d889724c6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicao_arvore = arvore_decisao.predict(X_test)\n",
        "acuracia_arvore = accuracy_score(y_test, predicao_arvore)\n",
        "report_arvore = classification_report(y_test, predicao_arvore)\n",
        "matriz_arvore = confusion_matrix(y_test, predicao_arvore)\n",
        "\n",
        "conclusao = classification_report(y_test, predicao_arvore)\n",
        "\n",
        "print(\"Acurácia:\", acuracia_arvore)\n",
        "print(\"Classificação:\")\n",
        "print(report_arvore)\n",
        "print(\"Matriz da confusão:\")\n",
        "print(matriz_arvore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQMiPFbKSv7J",
        "outputId": "22ef0a79-ae25-45c6-ea4c-01648c27365d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.9635416666666666\n",
            "Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.00      0.00      0.00         2\n",
            "          65       0.00      0.00      0.00         1\n",
            "          67       0.00      0.00      0.00         0\n",
            "          71       1.00      1.00      1.00         1\n",
            "          73       1.00      1.00      1.00         2\n",
            "          74       1.00      1.00      1.00         1\n",
            "          75       1.00      1.00      1.00         1\n",
            "          77       1.00      1.00      1.00         1\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00         3\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       1.00      1.00      1.00         2\n",
            "          83       1.00      1.00      1.00         4\n",
            "          84       1.00      1.00      1.00         2\n",
            "          85       1.00      1.00      1.00         2\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         4\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         1\n",
            "          91       1.00      1.00      1.00         1\n",
            "          92       1.00      1.00      1.00         2\n",
            "          93       1.00      1.00      1.00         3\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         1\n",
            "          96       1.00      1.00      1.00         1\n",
            "          97       1.00      1.00      1.00         4\n",
            "          98       1.00      1.00      1.00         1\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         4\n",
            "         102       1.00      1.00      1.00         2\n",
            "         103       1.00      1.00      1.00         3\n",
            "         104       1.00      1.00      1.00         2\n",
            "         105       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         4\n",
            "         107       1.00      1.00      1.00         1\n",
            "         108       1.00      1.00      1.00         4\n",
            "         109       1.00      1.00      1.00         4\n",
            "         110       1.00      1.00      1.00         4\n",
            "         111       1.00      1.00      1.00         4\n",
            "         112       1.00      1.00      1.00         1\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      1.00      1.00         2\n",
            "         115       1.00      1.00      1.00         4\n",
            "         116       1.00      1.00      1.00         2\n",
            "         117       1.00      1.00      1.00         6\n",
            "         118       1.00      1.00      1.00         4\n",
            "         119       1.00      1.00      1.00         6\n",
            "         120       1.00      1.00      1.00         2\n",
            "         121       1.00      1.00      1.00         2\n",
            "         122       1.00      1.00      1.00         5\n",
            "         123       1.00      1.00      1.00         3\n",
            "         124       1.00      1.00      1.00         5\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         2\n",
            "         128       1.00      1.00      1.00         4\n",
            "         130       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         137       1.00      1.00      1.00         1\n",
            "         138       1.00      1.00      1.00         1\n",
            "         140       1.00      1.00      1.00         1\n",
            "         142       1.00      1.00      1.00         2\n",
            "         143       1.00      1.00      1.00         3\n",
            "         144       1.00      1.00      1.00         1\n",
            "         145       1.00      1.00      1.00         1\n",
            "         146       1.00      1.00      1.00         2\n",
            "         147       1.00      1.00      1.00         1\n",
            "         151       1.00      1.00      1.00         2\n",
            "         152       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         1\n",
            "         155       1.00      1.00      1.00         2\n",
            "         156       1.00      1.00      1.00         1\n",
            "         158       1.00      1.00      1.00         2\n",
            "         159       0.50      1.00      0.67         1\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       1.00      1.00      1.00         1\n",
            "         162       1.00      1.00      1.00         2\n",
            "         163       1.00      1.00      1.00         1\n",
            "         165       1.00      1.00      1.00         1\n",
            "         167       1.00      1.00      1.00         1\n",
            "         168       1.00      1.00      1.00         2\n",
            "         170       1.00      1.00      1.00         1\n",
            "         171       1.00      1.00      1.00         2\n",
            "         173       1.00      1.00      1.00         2\n",
            "         175       1.00      1.00      1.00         1\n",
            "         177       0.00      0.00      0.00         0\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      1.00      1.00         1\n",
            "         181       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         1\n",
            "         187       1.00      1.00      1.00         1\n",
            "         189       0.00      0.00      0.00         0\n",
            "         190       0.00      0.00      0.00         1\n",
            "         191       0.00      0.00      0.00         1\n",
            "         193       1.00      1.00      1.00         1\n",
            "         196       1.00      1.00      1.00         1\n",
            "         197       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.96       192\n",
            "   macro avg       0.89      0.90      0.90       192\n",
            "weighted avg       0.96      0.96      0.96       192\n",
            "\n",
            "Matriz da confusão:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [2 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Conclusão:\")\n",
        "print(conclusao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrX7JIJ2Tgkt",
        "outputId": "f988c882-9247-4016-f03d-bf62d788ba2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conclusão:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.00      0.00      0.00         2\n",
            "          65       0.00      0.00      0.00         1\n",
            "          67       0.00      0.00      0.00         0\n",
            "          71       1.00      1.00      1.00         1\n",
            "          73       1.00      1.00      1.00         2\n",
            "          74       1.00      1.00      1.00         1\n",
            "          75       1.00      1.00      1.00         1\n",
            "          77       1.00      1.00      1.00         1\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00         3\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       1.00      1.00      1.00         2\n",
            "          83       1.00      1.00      1.00         4\n",
            "          84       1.00      1.00      1.00         2\n",
            "          85       1.00      1.00      1.00         2\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         4\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         1\n",
            "          91       1.00      1.00      1.00         1\n",
            "          92       1.00      1.00      1.00         2\n",
            "          93       1.00      1.00      1.00         3\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         1\n",
            "          96       1.00      1.00      1.00         1\n",
            "          97       1.00      1.00      1.00         4\n",
            "          98       1.00      1.00      1.00         1\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         4\n",
            "         102       1.00      1.00      1.00         2\n",
            "         103       1.00      1.00      1.00         3\n",
            "         104       1.00      1.00      1.00         2\n",
            "         105       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         4\n",
            "         107       1.00      1.00      1.00         1\n",
            "         108       1.00      1.00      1.00         4\n",
            "         109       1.00      1.00      1.00         4\n",
            "         110       1.00      1.00      1.00         4\n",
            "         111       1.00      1.00      1.00         4\n",
            "         112       1.00      1.00      1.00         1\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      1.00      1.00         2\n",
            "         115       1.00      1.00      1.00         4\n",
            "         116       1.00      1.00      1.00         2\n",
            "         117       1.00      1.00      1.00         6\n",
            "         118       1.00      1.00      1.00         4\n",
            "         119       1.00      1.00      1.00         6\n",
            "         120       1.00      1.00      1.00         2\n",
            "         121       1.00      1.00      1.00         2\n",
            "         122       1.00      1.00      1.00         5\n",
            "         123       1.00      1.00      1.00         3\n",
            "         124       1.00      1.00      1.00         5\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         2\n",
            "         128       1.00      1.00      1.00         4\n",
            "         130       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         137       1.00      1.00      1.00         1\n",
            "         138       1.00      1.00      1.00         1\n",
            "         140       1.00      1.00      1.00         1\n",
            "         142       1.00      1.00      1.00         2\n",
            "         143       1.00      1.00      1.00         3\n",
            "         144       1.00      1.00      1.00         1\n",
            "         145       1.00      1.00      1.00         1\n",
            "         146       1.00      1.00      1.00         2\n",
            "         147       1.00      1.00      1.00         1\n",
            "         151       1.00      1.00      1.00         2\n",
            "         152       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         1\n",
            "         155       1.00      1.00      1.00         2\n",
            "         156       1.00      1.00      1.00         1\n",
            "         158       1.00      1.00      1.00         2\n",
            "         159       0.50      1.00      0.67         1\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       1.00      1.00      1.00         1\n",
            "         162       1.00      1.00      1.00         2\n",
            "         163       1.00      1.00      1.00         1\n",
            "         165       1.00      1.00      1.00         1\n",
            "         167       1.00      1.00      1.00         1\n",
            "         168       1.00      1.00      1.00         2\n",
            "         170       1.00      1.00      1.00         1\n",
            "         171       1.00      1.00      1.00         2\n",
            "         173       1.00      1.00      1.00         2\n",
            "         175       1.00      1.00      1.00         1\n",
            "         177       0.00      0.00      0.00         0\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      1.00      1.00         1\n",
            "         181       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         1\n",
            "         187       1.00      1.00      1.00         1\n",
            "         189       0.00      0.00      0.00         0\n",
            "         190       0.00      0.00      0.00         1\n",
            "         191       0.00      0.00      0.00         1\n",
            "         193       1.00      1.00      1.00         1\n",
            "         196       1.00      1.00      1.00         1\n",
            "         197       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.96       192\n",
            "   macro avg       0.89      0.90      0.90       192\n",
            "weighted avg       0.96      0.96      0.96       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, random_state=50)\n",
        "\n",
        "y_train_encondeder = label_encoder.fit_transform(y_train)\n",
        "\n",
        "y_test_encondeder = label_encoder.transform(y_test)\n",
        "\n",
        "classificador = KNeighborsClassifier()\n",
        "\n",
        "classificador.fit(X_train, y_train_encondeder)\n",
        "\n",
        "previsoes = classificador.predict(X_test)\n",
        "\n",
        "precisao = accuracy_score(y_test_encondeder, previsoes)\n",
        "\n",
        "print(\"Previsões:\", previsoes)\n",
        "print(\"Precisão do Modelo:\", precisao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrKHUnlDY7Pt",
        "outputId": "242a7414-0ce5-4a5f-c44f-1e823113a0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previsões: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0\n",
            " 1 0 0 1 0 0 0]\n",
            "Precisão do Modelo: 0.7395833333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "k = 5\n",
        "classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "classifier.fit(X_train_scaled, y_train_encondeder)\n",
        "\n",
        "predictions = classifier.predict(X_test_scaled)\n",
        "\n",
        "report = classification_report(y_test_encondeder, predictions)\n",
        "\n",
        "accuracy = accuracy_score(y_test_encondeder, predictions)\n",
        "\n",
        "print(\"Predictions:\", predictions)\n",
        "print(\"Model Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "48JowPyWbVHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdd057d-d7f7-42dd-ab6c-0e645e8ee711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0\n",
            " 1 0 0 1 0 0 0]\n",
            "Model Accuracy: 0.734375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = classifier.predict(X_test_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_test_encondeder, result, labels=[0,1,2])\n",
        "# pega o resultado em um objeto\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AF2n8FZIbdi_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "739317cb-b2c3-4561-a38f-3831c618d9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}